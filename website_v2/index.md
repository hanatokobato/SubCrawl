---
layout: default
---

## About

SubCrawl aims to support the research and development of machine translation systems, information extraction, and other language processing techniques. Researchers at Stanford and Google created this corpus by crawling the internet for movie and tv subtitles, then aligining their captions. [Fork us on GitHub!](https://github.com/rpryzant/SubCrawl)

## Features

* A **large** corpus of with translations for over 3.2 million sentences
* Translations of **casual**, and **colloquial** language, domains that are hard to find in JA-EN MT. 
* **Pre-processed** data, including tokenized train/dev/test splits.
* **Code** for making your own dataset and **tools** for manipulating MT data.

## Corpus Contents



| *Split* | *Phrase Pairs* |
|---------|----------------|
| Raw     | 3243887        |
| Train   | 3239888        |
| Dev     | 2000           |
| Test    | 3001           |


| Corpus        | Vocab Size             |
|---------------|------------------------|
| Pre-Tokenized | 16000                  |
| Raw English   | 379558 unique words    |
| Raw Japanese  | 6113 unique characters |




## Samples
* some samples 
* live demo of a trained model?

## Download
* [Code]()
* [Raw corpus]()
* [Official splits]()
* [Example tokenization]()
  * BPE with vocab size of 16000 


## Cite

```
archive or emnlp citation
```

