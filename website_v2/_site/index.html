<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="description" content="DESCRIPTION HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>SubCrawl</title>
  <link rel="stylesheet" href="css/main.css">
<img src="img/ja.png" alt="Reid Pryzant" class="headshot">
<img src="img/en.png" alt="Reid Pryzant" class="headshot-right">
</br>
</head>
<body>
  <div class="container">
    <h1><a href="./">SubCrawl</a></h1>
    <h2 id="about">About</h2>

<p>SubCrawl aims to support the research and development of machine translation systems, information extraction, and other language processing techniques. Researchers at Stanford and Google created this corpus by crawling the internet for movie and tv subtitles, then aligining their captions. <a href="https://github.com/rpryzant/SubCrawl">Fork us on GitHub!</a></p>

<h2 id="features">Features</h2>

<ul>
  <li>A <strong>large</strong> corpus of with translations for over 3.2 million sentences</li>
  <li>Translations of <strong>casual</strong>, and <strong>colloquial</strong> language, domains that are hard to find in JA-EN MT.</li>
  <li><strong>Pre-processed</strong> data, including tokenized train/dev/test splits.</li>
  <li><strong>Code</strong> for making your own dataset and <strong>tools</strong> for manipulating MT data.</li>
</ul>

<h2 id="corpus-contents">Corpus Contents</h2>

<table>
  <thead>
    <tr>
      <th><em>Split</em></th>
      <th><em>Phrase Pairs</em></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Raw</td>
      <td>3243887</td>
    </tr>
    <tr>
      <td>Train</td>
      <td>3239888</td>
    </tr>
    <tr>
      <td>Dev</td>
      <td>2000</td>
    </tr>
    <tr>
      <td>Test</td>
      <td>3001</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th>Corpus</th>
      <th>Vocab Size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Pre-Tokenized</td>
      <td>16000</td>
    </tr>
    <tr>
      <td>Raw English</td>
      <td>379558 unique words</td>
    </tr>
    <tr>
      <td>Raw Japanese</td>
      <td>6113 unique characters</td>
    </tr>
  </tbody>
</table>

<h2 id="samples">Samples</h2>
<ul>
  <li>some samples</li>
  <li>live demo of a trained model?</li>
</ul>

<h2 id="download">Download</h2>
<ul>
  <li><a href="">Code</a></li>
  <li><a href="">Raw corpus</a></li>
  <li><a href="">Official splits</a></li>
  <li><a href="">Example tokenization</a>
    <ul>
      <li>BPE with vocab size of 16000</li>
    </ul>
  </li>
</ul>

<h2 id="cite">Cite</h2>

<div class="highlighter-rouge"><pre class="highlight"><code>archive or emnlp citation
</code></pre>
</div>


  </div>

<img src="img/stanford.png" alt="Reid Pryzant" class="headshot">
<img src="img/brain.jpg" alt="Reid Pryzant" class="headshot-right">
</br>
</br>
</br>
</body>
</html>
